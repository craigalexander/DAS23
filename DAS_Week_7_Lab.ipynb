{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPI3vG+K9K9QqALhXx/0/Bw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/craigalexander/DAS23/blob/main/DAS_Week_7_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis Skills - Confidence Intervals and Model Parameter Selection\n",
        "\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "In this lab we construct confidence intervals for the parameters in simple and multiple linear regression models. We consider confidence intervals based on theoretical results when standard assumptions hold. We will also consider how to use confidence intervals for variable selection and finish by considering a model selection strategy based on objective measures for model comparisons.\n",
        "\n",
        "For this lab, we will use the following libraries in Python:"
      ],
      "metadata": {
        "id": "DoRg2Og1uLOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbr_Y4tAsbTY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's continue with the teaching evaluations data that we first saw in Lab 6 by fitting the multiple regression with one numerical and one categorical predictor. In this model:\n",
        "\n",
        "* $y$: outcome variable of instructor evaluation `score`\n",
        "* predictor variables\n",
        "    + $x_1$: numerical explanatory/predictor variable of `age`\n",
        "    + $x_2$: categorical explanatory/predictor variable of `gender`\n",
        "\n"
      ],
      "metadata": {
        "id": "grDGjm-nu5au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evals_url = 'https://github.com/craigalexander/DAS23/raw/main/Data/evals.csv'\n",
        "evals = pd.read_csv(evals_url,index_col=0) \n",
        "\n",
        "evals_score = evals[[\"score\",\"age\",\"gender\"]]\n",
        "# We will need to convert gender to a category\n",
        "evals_score['gender'] = evals_score.gender.astype('category')\n",
        "evals_score.dtypes # Print data types"
      ],
      "metadata": {
        "id": "VeHbL_CcvTn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, recall that we had two competing potential models to explain professors' teaching evaluation scores in Lab 6:\n",
        "\n",
        "1. Model 1: Parallel lines model (no interaction term) - both male and female professors have the same slope describing the associated effect of age on teaching score\n",
        "2. Model 2: Interaction model - allowing for male and female professors to have different slopes describing the associated effect of age on teaching score.\n",
        "\n",
        "Let's recall the regression models we fit. First, the regression with no \n",
        "interaction effect: note the use of `+` in the formula."
      ],
      "metadata": {
        "id": "t-BbmAxEvg8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_parallel = ols(\"score~ age + gender\",data=evals_score)\n",
        "result_parallel=model_parallel.fit() # Fit model\n",
        "\n",
        "print(result_parallel.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0sWUyprvxMe",
        "outputId": "917e6041-ae60-481e-e837-4bd67741ea7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  score   R-squared:                       0.039\n",
            "Model:                            OLS   Adj. R-squared:                  0.035\n",
            "Method:                 Least Squares   F-statistic:                     9.338\n",
            "Date:                Sun, 19 Feb 2023   Prob (F-statistic):           0.000106\n",
            "Time:                        14:53:29   Log-Likelihood:                -365.26\n",
            "No. Observations:                 463   AIC:                             736.5\n",
            "Df Residuals:                     460   BIC:                             748.9\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==================================================================================\n",
            "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------\n",
            "Intercept          4.4841      0.125     35.792      0.000       4.238       4.730\n",
            "gender[T.male]     0.1906      0.052      3.632      0.000       0.087       0.294\n",
            "age               -0.0087      0.003     -3.280      0.001      -0.014      -0.003\n",
            "==============================================================================\n",
            "Omnibus:                       28.579   Durbin-Watson:                   1.223\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.768\n",
            "Skew:                          -0.652   Prob(JB):                     7.67e-08\n",
            "Kurtosis:                       2.991   Cond. No.                         249.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second, the regression with an interaction effect: note the use of `*` in the formula."
      ],
      "metadata": {
        "id": "UXeHIWiLv-gO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_interaction = ols(\"score~ age*gender\",data=evals_score)\n",
        "result_interaction=model_interaction.fit() # Fit model\n",
        "\n",
        "print(result_interaction.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbwpSoexwDgm",
        "outputId": "1444b05b-f56b-49be-ffd8-aadadb49426b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  score   R-squared:                       0.051\n",
            "Model:                            OLS   Adj. R-squared:                  0.045\n",
            "Method:                 Least Squares   F-statistic:                     8.288\n",
            "Date:                Sun, 19 Feb 2023   Prob (F-statistic):           2.23e-05\n",
            "Time:                        14:53:33   Log-Likelihood:                -362.26\n",
            "No. Observations:                 463   AIC:                             732.5\n",
            "Df Residuals:                     459   BIC:                             749.1\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "======================================================================================\n",
            "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "Intercept              4.8830      0.205     23.795      0.000       4.480       5.286\n",
            "gender[T.male]        -0.4460      0.265     -1.681      0.094      -0.968       0.076\n",
            "age                   -0.0175      0.004     -3.919      0.000      -0.026      -0.009\n",
            "age:gender[T.male]     0.0135      0.006      2.446      0.015       0.003       0.024\n",
            "==============================================================================\n",
            "Omnibus:                       33.183   Durbin-Watson:                   1.242\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.598\n",
            "Skew:                          -0.702   Prob(JB):                     4.15e-09\n",
            "Kurtosis:                       3.168   Cond. No.                         771.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that, together with the estimated parameter values, the tables include other information about each estimated parameter in the model, namely:\n",
        "\n",
        "Notice that, together with the estimated parameter values, the tables include other information about each estimated parameter in the model, namely:\n",
        "\n",
        "* **std err**: the standard error of each parameter estimate\n",
        "* **t**: the test statistic value used to test the null hypothesis that the population parameter is zero\n",
        "* **P >|t|**: the $p$ value associated with the test statistic under the null hypothesis\n",
        "* **[0.025** and **0.975]**: the lower and upper bounds of the 95% confidence interval for the population parameter\n",
        "\n",
        "These values are calculated using the theoretical results based on the standard assumptions that you will have seen in *Regression Modelling* in first semester."
      ],
      "metadata": {
        "id": "90wcPun8wQTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**\n",
        "\n",
        "What is the 95% Confidence Interval for the difference, on average, between the (linear) effect age has on the evaluation scores of male professors and the (linear) effect age has on the evaluation scores of female professors?"
      ],
      "metadata": {
        "id": "mdk-geKqw842"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**\n",
        "\n",
        "By just considering the simpler parallel lines model, what can we say about the the difference, on average, between the evaluation scores of male and female professors when age is taken into account?"
      ],
      "metadata": {
        "id": "rbtItlYBxMVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference using Confidence Intervals\n",
        "\n",
        "# Simple Linear Regression: $E(y_i) = \\alpha + \\beta x_i$ \n",
        "\n",
        "As we have seen, \n",
        "\n",
        "> A confidence interval gives a range of plausible values for a population parameter.\n",
        "\n",
        "We can therefore use the confidence interval for $\\beta$ to state a range of plausible values and, just as usefully, what values are **not** plausible.  The most common values to compare the confidence interval of $\\beta$ with is 0 (zero), since $\\beta = 0$ says there is *no* (linear) relationship between the outcome variable ($y$) and the explanatory variable ($x$).  Therefore, if 0 lies within the confidence interval for $\\beta$ then there is insufficient evidence of a linear relationship between $y$ and $x$.  However, if 0 does **not** lie within the confidence interval, then we conclude that $\\beta$ is significantly different from zero and therefore that there is evidence of a linear relationship between $y$ and $x$.\n",
        "\n",
        "Let's use the confidence interval based on theoretical results for slope parameter in the SLR model applied to the teacher evaluation scores with `age` as the the single explanatory variable and the instructors' evaluation `score`s as the outcome variable. "
      ],
      "metadata": {
        "id": "zsF9Ybi2xY6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple = ols('score~age',data=evals_score)\n",
        "result_simple = model_simple.fit()\n",
        "\n",
        "print(result_simple.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQRja33OwBCV",
        "outputId": "f1d2f903-2c4e-4a4c-8cef-0ce9fd0ba43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  score   R-squared:                       0.011\n",
            "Model:                            OLS   Adj. R-squared:                  0.009\n",
            "Method:                 Least Squares   F-statistic:                     5.342\n",
            "Date:                Sun, 19 Feb 2023   Prob (F-statistic):             0.0213\n",
            "Time:                        14:53:42   Log-Likelihood:                -371.81\n",
            "No. Observations:                 463   AIC:                             747.6\n",
            "Df Residuals:                     461   BIC:                             755.9\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      4.4619      0.127     35.195      0.000       4.213       4.711\n",
            "age           -0.0059      0.003     -2.311      0.021      -0.011      -0.001\n",
            "==============================================================================\n",
            "Omnibus:                       30.047   Durbin-Watson:                   1.211\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.658\n",
            "Skew:                          -0.670   Prob(JB):                     2.98e-08\n",
            "Kurtosis:                       3.032   Cond. No.                         249.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**\n",
        "\n",
        "Based on the fitted SLR model, is there evidence that there is a statistically significant linear relationship between the age of the professors and their teaching evaluation score?"
      ],
      "metadata": {
        "id": "PIjjj-LGyJV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Regression $E(y_i) = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ...$\n",
        "\n",
        "Consider, again, the fitted interaction model for `score` with `age` and `gender` as the two explanatory variables."
      ],
      "metadata": {
        "id": "ILWFOlYryVAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_interaction.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY7ZZ9V2y7V8",
        "outputId": "fcc0739a-5c30-463e-f6bb-91c47e0b93cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  score   R-squared:                       0.051\n",
            "Model:                            OLS   Adj. R-squared:                  0.045\n",
            "Method:                 Least Squares   F-statistic:                     8.288\n",
            "Date:                Sun, 19 Feb 2023   Prob (F-statistic):           2.23e-05\n",
            "Time:                        14:53:46   Log-Likelihood:                -362.26\n",
            "No. Observations:                 463   AIC:                             732.5\n",
            "Df Residuals:                     459   BIC:                             749.1\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "======================================================================================\n",
            "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "Intercept              4.8830      0.205     23.795      0.000       4.480       5.286\n",
            "gender[T.male]        -0.4460      0.265     -1.681      0.094      -0.968       0.076\n",
            "age                   -0.0175      0.004     -3.919      0.000      -0.026      -0.009\n",
            "age:gender[T.male]     0.0135      0.006      2.446      0.015       0.003       0.024\n",
            "==============================================================================\n",
            "Omnibus:                       33.183   Durbin-Watson:                   1.242\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.598\n",
            "Skew:                          -0.702   Prob(JB):                     4.15e-09\n",
            "Kurtosis:                       3.168   Cond. No.                         771.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**\n",
        "\n",
        "Based on the fitted interaction model, is there evidence that we should allow for different rates of change for male and female professors' teaching scores as they get older?"
      ],
      "metadata": {
        "id": "e12_ITNtzHqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variable Selection using Confidence Intervals\n",
        "\n",
        "When there is more than one explanatory variable in a model, the parameter associated with each explanatory variable is interpreted as the change in the mean response based on a 1-unit change in the corresponding explanatory variable **keeping all other variables held constant**.  Therefore, care must be taken when interpreting the confidence intervals of each parameter by acknowledging that each are plausible values **conditional on all the other explanatory variables in the model**.\n",
        "\n",
        "Because of the interdependence between the parameter estimates and the variables included in the model, choosing which variables to include in the model is a rather complex task.  We will introduce some of the ideas in the simple case where we have 2 potential explanatory variables ($x_1$ and $x_2$)  and use confidence intervals to decide which variables will be useful in predicting the outcome variable ($y$).\n",
        "\n",
        "One approach is to consider a hierarchy of models:\n",
        "\n",
        "$$\\hat y_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i}$$   \n",
        "$$\\hat y_i = \\alpha + \\beta_1 x_{1i} \\qquad \\qquad \\qquad \\hat y_i = \\alpha + \\beta_2 x_{2i}$$   \n",
        "$$\\hat y_i = \\alpha$$\n",
        "\n",
        "Within this structure we might take a top-down approach:\n",
        "\n",
        "1. Fit the most general model, i.e. $\\hat y_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i}$ since we believe this is likely to provide a good description of the data.\n",
        "2. Construct confidence intervals for $\\beta_1$ and $\\beta_2$\n",
        "\n",
        "    (a) If both intervals exclude 0 then retain the model with both $x_1$ and $x_2$.\n",
        "\n",
        "    (b) If the interval for $\\beta_1$ contains 0 but that for $\\beta_2$ does not, fit the model with $x_2$ alone.\n",
        "\n",
        "    (c) If the interval for $\\beta_2$ contains 0 but that for $\\beta_1$ does not, fit the model with $x_1$ alone.\n",
        "    \n",
        "    (d) If both intervals include 0 it may still be that a model with one variable is useful. In this case the two models with the single variables should be fitted and intervals for $\\beta_1$ and $\\beta_2$ constructed and compared with 0.\n",
        "\n",
        "If we have only a few explanatory variables, then an extension of the strategy outlined above would be effective, i.e. start with the full model and simplify by removing terms until no further terms can be removed.  When the number of explanatory variables is large the problem becomes more difficult. We will consider this more challenging situation in the next section.\n",
        "\n",
        "Recall that as well as `age` and `gender`, there is also a potential explanatory variable `bty_avg` in the `evals` data, i.e. the numerical variable of the average beauty score from a panel of six students' scores between 1 and 10. We can fit the multiple regression model with the two continuous explanatory variables `age` and `bty_avg` as follows:"
      ],
      "metadata": {
        "id": "E90Iy3ENzXRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlr = ols('score ~ age + bty_avg',data=evals)\n",
        "result_mlr = model_mlr.fit()\n",
        "print(result_mlr.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZyYRQvRz8TS",
        "outputId": "e8888c85-15ca-4d08-8442-763519193979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  score   R-squared:                       0.038\n",
            "Model:                            OLS   Adj. R-squared:                  0.034\n",
            "Method:                 Least Squares   F-statistic:                     9.031\n",
            "Date:                Sun, 19 Feb 2023   Prob (F-statistic):           0.000142\n",
            "Time:                        14:53:49   Log-Likelihood:                -365.56\n",
            "No. Observations:                 463   AIC:                             737.1\n",
            "Df Residuals:                     460   BIC:                             749.5\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      4.0547      0.170     23.870      0.000       3.721       4.389\n",
            "age           -0.0031      0.003     -1.148      0.251      -0.008       0.002\n",
            "bty_avg        0.0607      0.017      3.548      0.000       0.027       0.094\n",
            "==============================================================================\n",
            "Omnibus:                       32.361   Durbin-Watson:                   1.269\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.864\n",
            "Skew:                          -0.700   Prob(JB):                     6.00e-09\n",
            "Kurtosis:                       3.021   Cond. No.                         339.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**\n",
        "\n",
        "Following the process outlined above for choosing which variables to include in the model, what would be your next step after fitting this MLR model"
      ],
      "metadata": {
        "id": "qE8RqzJUz2tI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model comparisons using objective criteria\n",
        "\n",
        "As was noted in the last section, when the number of potential predictor variables is large the problem of selecting which variables to include in the final model becomes more difficult.  The selection of a final regression model always involves a compromise:\n",
        "\n",
        "* Predictive accuracy (improved by including more predictors)\n",
        "* Parsimony and interpretability (achieved by having less predictors)\n",
        "\n",
        "\n",
        "There are many objective criteria for comparing different models applied to the same data set. All of them trade off the two objectives above, i.e.  fit to the data against complexity. Common examples include:\n",
        "\n",
        "1.  The $R^2_{adj}$ values, i.e. the proportions of total variation of response variable explained by the models.\n",
        "\n",
        "$$R_{adj}^2 = 1 - \\frac{RSS/(n-p-1)}{SST/(n-1)} = 100 \\times \\Bigg[ 1-\\frac{\\sum_{i=1}^n(y_i-\\hat y_i)^2/(n-p-1)}{\\sum_{i=1}^n(y_i-\\bar y_i)^2/(n-1)}\\Bigg]$$\n",
        "\n",
        "  * where \n",
        "      - $n$ is the sample size\n",
        "      - $p$ is the number of parameters in the model\n",
        "      - $RSS$ is the residual sum of squares from the fitted model\n",
        "      - $SST$ is the total sum of squares around the mean response.\n",
        "  * F ratios and the F-distribution can be used to compare the $R_{adj}^2$ values\n",
        "  * These can only be used for nested models, i.e. where one model is a particular case of the other\n",
        "\n",
        "2. Akaike's Information Criteria (AIC) \n",
        "\n",
        "$$AIC = -2(\\mbox{log-likeihood})+2p = n\\mbox{ln}\\Bigg(\\frac{RSS}{n}\\Bigg)+2p$$\n",
        "\n",
        "  * A value based on the maximum likelihood function of the parameters in the fitted model penalized by the number of parameters in the model\n",
        "  * Can be used to compare any models fitted to the same response variable \n",
        "  * The smaller the AIC the 'better' the model, i.e. no distributional results are employed to assess differences \n",
        "\n",
        "3. Bayesian Information Criteria \n",
        "\n",
        "$$BIC = -2(\\mbox{log-likeihood})+\\mbox{ln}(n)p$$\n",
        "A popular data analysis strategy which we shall adopt is to calculate $R_{adj}^2$, $AIC$ and $BIC$ and prefer the models which **minimize** $AIC$ and $BIC$ and that **maximize** $R_{adj}^2$.\n",
        "\n",
        "To illustrate, let's return to the `evals` data and the MLR on the teaching evaluation score `score` with the two continuous explanatory variables `age` and `bty_avg` and compare this with the SLR model with just `bty_avg`.  \n",
        "\n",
        "To access these measures for model comparisons we can view these values in the `summary` output from our `ols` object, or can access these individually as follows (**Note - there are slight differences between the objective criteria values when compared to R. This is due to a difference in the fitting process for `ols` when compared to `lm`**):"
      ],
      "metadata": {
        "id": "DgyvXygr1IgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit SLR for bty_avg\n",
        "model_simple2 = ols('score~bty_avg',data=evals)\n",
        "result_simple2 = model_simple2.fit()\n",
        "\n",
        "# Obtain objective criteria for SLR for age\n",
        "print(result_simple.rsquared_adj) # R2 value\n",
        "print(result_simple.aic) # AIC value\n",
        "print(result_simple.bic) # BIC value\n",
        "\n",
        "# Obtain objective criteria for SLR for bty_avg\n",
        "print(result_simple2.rsquared_adj) # R2 value\n",
        "print(result_simple2.aic) # AIC value\n",
        "print(result_simple2.bic) # BIC value\n",
        "\n",
        "# Obtain objective criteria for MLR for age and bty_avg\n",
        "print(result_mlr.rsquared_adj) # R2 value\n",
        "print(result_mlr.aic) # AIC value\n",
        "print(result_mlr.bic) # BIC value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxH7k3XM1u-Y",
        "outputId": "90146341-cd81-4965-d8f7-a48302026344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00931149520785346\n",
            "747.6163026279014\n",
            "755.8917567360738\n",
            "0.03292903378612022\n",
            "736.44490898058\n",
            "744.7203630887524\n",
            "0.033597442612292805\n",
            "737.1193581246387\n",
            "749.5325392868974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**\n",
        "\n",
        "Based on these values and the model comparison strategy outlined above, which of these three models would you favour?"
      ],
      "metadata": {
        "id": "pkaO7SOn4Kpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A final word on model selection\n",
        "\n",
        "A great deal of care should be taken in selecting predictors for a model because the values of the regression coefficients depend upon the variables in the model. Therefore, the predictors included and the order in which they are entered into the model can have a great impact. In an ideal world, predictors should be selected based on past research and new predictors should be added to existing models based on the theoretical importance of the variables.  One thing not to do is select hundreds of random predictors, bung them all into a regression analysis and hope for the best. \n",
        "\n",
        "But in practice there are automatic strategies, such as *Stepwise* and *Best Subsets* regression, based on systematically searching through the entire list of variables not in the current model to make decisions on whether each should be included. These strategies need to be handled with care, and a proper discussion of them is beyond this course. Our best strategy is a mixture of judgement on what variables should be included as potential explanatory variables, together with parameter interval estimation and a comparison of objective measures for assessing different models. The judgement should be made in the light of advice from the problem context.\n",
        "\n",
        "**Golden rule for modelling**\n",
        "\n",
        "> The key to modelling data is to only use the objective measures as a rough guide. In the end the choice of model will involve your own judgement. You have to be able to defend why you chose a particular model."
      ],
      "metadata": {
        "id": "8DZB-Fp94vxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Tasks: Model Parameter Selection\n",
        "\n",
        "**Question 1**\n",
        "\n",
        "Data were collected on the characteristics of homes in the American city of Los Angeles (LA) in 2010 and can be found in the file `LAhomes.csv` on the Moodle page.  The data contain the following variables:\n",
        "\n",
        "* `city` - the district of LA where the house was located\n",
        "* `type` - either `SFR` (Single Family Residences) or `Condo/Twh` (Condominium/Town House)\n",
        "* `bed` - the number of bedrooms\n",
        "* `bath` - the number of bathrooms\n",
        "* `garage` - the number of car spaces in the garage\n",
        "* `sqft` - the floor area of the house (in square feet)\n",
        "* `pool` - `Y` if the house has a pool\n",
        "* `spa` - `TRUE` if the house has a spa\n",
        "* `price` - the most recent sales price ($US)\n",
        "\n",
        "We are interested in exploring the relationships betwen `price` and the other variables.\n",
        "\n",
        "Read the data into an object called `LAhomes` and answer the following questions.\n",
        "\n",
        "\n",
        "a. By looking at the univariate and bivariate distributions on the `price` and `sqft` variables below, what would be a sensible way to proceed if we wanted to model this data?  What care must be taken if you were to proceed this way?"
      ],
      "metadata": {
        "id": "mJ4PT-PX45bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "LAhomes_url = 'https://github.com/craigalexander/DAS23/raw/main/Data/LAhomes.csv'\n",
        "LAhomes = pd.read_csv(LAhomes_url,index_col=0) \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rs9Y6Tf35Ier"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b.  Fit the simple linear model with `log(price)` as the response and `log(sqft)` as the predictor. Display the fitted model on a scatterplot of the data."
      ],
      "metadata": {
        "id": "TxKwIGI4B30h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OJHzoTsmB8xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Repeat the analysis in part b. but with the log of the number of bathrooms (`bath`) as the single explanatory variable."
      ],
      "metadata": {
        "id": "EM6KqmvFDU45"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJvB1fYZDYY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Fit the multiple linear regression model using the **log transform of all the variables** `price` (as the response) and both `sqft` and `bath` (as the explanatory variables). Calculate the point and interval estimates of the coefficients of the two predictors separately. Compare their point and interval estimates to those you calculated in parts b. and c.   Can you account for the differences?"
      ],
      "metadata": {
        "id": "MewhHXSlEYLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "uD_o36wuEZX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Using the objective measures for model comparisons, which of the models in parts b., c. and d. would you favour?  Is this consistent with your conclusions in part d.?"
      ],
      "metadata": {
        "id": "SnqTDkuNE0i5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7Tw5H3nE1we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n",
        "\n",
        "You have been asked to determine the pricing of a New York City (NYC) Italian restaurant's dinner menu such that it is competitively positioned with other high-end Italian restaurants by analyzing pricing data that have been collected in order to produce a regression model to predict the price of dinner.\n",
        "\n",
        "Data from surveys of customers of 168 Italian restaurants in the target area are available. The data can be found in the file `restNYC.csv` on the Moodle page.  Each row represents one customer survey from Italian restaurants in NYC and includes the key variables:\n",
        "\n",
        "* `Price` - price (in $US) of dinner (including a tip and one drink)\n",
        "* `Food` - customer rating of the food (from 1 to 30)\n",
        "* `Decor` - customer rating fo the decor (from 1 to 30)\n",
        "* `Service` - customer rating of the service (from 1 to 30)\n",
        "* `East` - dummy variable with the value 1 if the restaurant is east of Fifth Avenue, 0 otherwise\n",
        "\n",
        "\n",
        "a. Produce an informative set of graphical and numerical summaries which illuminate the relationships between pairs of variables.  Where do you see the strongest evidence of relationships between `price` and the potential explanatory variables?  Is there evidence of multicollineatity in the data? (Hint - you may find the `PairGrid` function in `seaborn` useful)"
      ],
      "metadata": {
        "id": "mJ_IvOL4FUDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "restNYC_url = 'https://github.com/craigalexander/DAS23/raw/main/Data/restNYC.csv'\n",
        "restNYC = pd.read_csv(restNYC_url,index_col=0,encoding = 'unicode_escape') \n",
        "restNYC['East'] = evals_score.gender.astype('category')\n",
        "restNYC=restNYC.drop('Case',axis=1)"
      ],
      "metadata": {
        "id": "aRGApdC7F5w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Fit the simple linear model with `Price` as the response and `Service` as the predictor and  display the fitted model on a scatterplot of the data."
      ],
      "metadata": {
        "id": "DR784-5AIsd9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wb41Ujv2IvUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now fit a multiple regressing model of `Price` on `Service`, `Food`, and `Decor`.  What happens to the significance of `Service` when additional variables were added to the model?"
      ],
      "metadata": {
        "id": "wgSJzAw4J0xm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "usEpeZniJ1cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. What is the correct interpretation of the coefficient on `Service` in the linear model which regresses `Price` on `Service`, `Food`, and `Decor`?"
      ],
      "metadata": {
        "id": "etKpypktKBfW"
      }
    }
  ]
}